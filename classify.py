#!/usr/bin/env python3
"""
Simple command-line interface for AI-powered video classification
"""

import argparse
import json
import sys
from main_classifier import ReelClassifier

def main():
    parser = argparse.ArgumentParser(description="Classify videos from URLs using OpenAI CLIP")
    parser.add_argument("url", help="URL of the video to classify")
    parser.add_argument("--top-k", type=int, default=5, help="Number of top categories to show")
    parser.add_argument("--output", choices=["json", "pretty"], default="pretty", help="Output format")
    parser.add_argument("--frames", action="store_true", help="Show detailed frame-by-frame analysis")
    parser.add_argument("--no-audio", action="store_true", help="Disable audio processing (faster)")
    
    args = parser.parse_args()
    
    # Initialize classifier
    print("ğŸš€ Initializing AI Video Classifier with Audio Processing...")
    classifier = ReelClassifier()
    
    # Classify the video
    print(f"ğŸ¬ Processing: {args.url}")
    enable_audio = not args.no_audio
    if args.no_audio:
        print("â­ï¸ Audio processing disabled")
    
    result = classifier.classify_reel(args.url, args.top_k, enable_audio=enable_audio)
    
    # Handle errors
    if "error" in result:
        print(f"âŒ Error: {result['error']}", file=sys.stderr)
        sys.exit(1)
    
    # Output results
    if args.output == "json":
        print(json.dumps(result, indent=2))
    else:
        print("="*60)
        print("ğŸ¯ AI VIDEO CLASSIFICATION RESULTS")
        print("="*60)
        print(f"ğŸ“º Title: {result['title']}")
        print(f"â±ï¸  Duration: {result['duration']} seconds")
        print(f"ğŸ¯ Overall Confidence: {result['confidence_score']:.3f}")
        print(f"ğŸ–¼ï¸  Frames Analyzed: {result['total_frames_analyzed']}")
        print(f"ğŸµ Has Audio: {'Yes' if result['has_audio'] else 'No'}")
        
        print(f"\nğŸ† TOP {args.top_k} SPECIFIC CATEGORIES:")
        print("-" * 40)
        for i, (category, score) in enumerate(result['top_categories'].items(), 1):
            print(f"{i:2d}. {category:<35} ({score:.3f})")
        
        print(f"\nğŸŒ BROADER CATEGORY GROUPS:")
        print("-" * 40)
        for i, (category, score) in enumerate(result['broader_categories'].items(), 1):
            print(f"{i:2d}. {category.replace('_', ' ').title():<35} ({score:.3f})")
        
        print(f"\nğŸ”– VISUAL TAGS:")
        print("-" * 20)
        print(", ".join(result['visual_tags']))
        
        # Show audio analysis if available
        if result['audio_keywords']:
            print(f"\nğŸ™ï¸ AUDIO KEYWORDS:")
            print("-" * 20)
            print(", ".join(result['audio_keywords']))
        
        if result['transcript']:
            print(f"\nğŸ“ TRANSCRIPT:")
            print("-" * 20)
            transcript_preview = result['transcript'][:300] + "..." if len(result['transcript']) > 300 else result['transcript']
            print(f"{transcript_preview}")
        
        print(f"\nğŸ·ï¸ ALL COMBINED TAGS:")
        print("-" * 20)
        print(", ".join(result['semantic_tags']))
        
        # Show frame-by-frame analysis if requested
        if args.frames and 'frame_by_frame' in result:
            print(f"\nğŸï¸  DETAILED FRAME ANALYSIS:")
            print("-" * 60)
            for frame_data in result['frame_by_frame']:
                print(f"Frame {frame_data['frame_number']:2d}: {frame_data['dominant_category']:<30} ({frame_data['confidence']:.3f})")
                top_3 = frame_data['top_categories']
                categories_str = " | ".join([f"{cat}: {score:.3f}" for cat, score in list(top_3.items())[:3]])
                print(f"         Top 3: {categories_str}")
                print()

if __name__ == "__main__":
    main()
